{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Assignment5_part2.ipynb","provenance":[],"collapsed_sections":["0H3J2MVK_5TW"]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9-final"}},"cells":[{"cell_type":"markdown","metadata":{"id":"OAqF8DSw_5TL"},"source":["# Getting Started Code for [Chunin Exams Food Track- CV'2021](https://www.aicrowd.com/challenges/chunin-exams-food-track-cv-2021) on AIcrowd\n","#### Author : Pulkit Gera"]},{"cell_type":"markdown","metadata":{"id":"0H3J2MVK_5TW"},"source":["## Download Necessary Packages ðŸ“š"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"psxJC7EC_5TX","executionInfo":{"status":"ok","timestamp":1618738079406,"user_tz":-330,"elapsed":6154,"user":{"displayName":"Dharmesh Gusai","photoUrl":"","userId":"00014665528927325987"}},"outputId":"2b0ae01b-df47-4408-cf60-1bc4699565d9"},"source":["!pip install aicrowd-cli"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting aicrowd-cli\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/18/2dcc043573e489f6134e4a76644f640874d3fa4d8f3e0593bf54a7c8b53a/aicrowd_cli-0.1.2-py3-none-any.whl (42kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 4.5MB/s \n","\u001b[?25hCollecting gitpython<4,>=3.1.12\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/99/98019716955ba243657daedd1de8f3a88ca1f5b75057c38e959db22fb87b/GitPython-3.1.14-py3-none-any.whl (159kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 7.6MB/s \n","\u001b[?25hCollecting requests-toolbelt<1,>=0.9.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 5.5MB/s \n","\u001b[?25hRequirement already satisfied: click<8,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (7.1.2)\n","Collecting rich<11,>=10.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/da/2a1f064dc620ab47f3f826ae085384084b71ea05c8c21d67f1dfc29189ab/rich-10.1.0-py3-none-any.whl (201kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 204kB 12.6MB/s \n","\u001b[?25hCollecting tqdm<5,>=4.56.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/8a/34efae5cf9924328a8f34eeb2fdaae14c011462d9f0e3fcded48e1266d1c/tqdm-4.60.0-py2.py3-none-any.whl (75kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 81kB 8.8MB/s \n","\u001b[?25hRequirement already satisfied: toml<1,>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from aicrowd-cli) (0.10.2)\n","Collecting requests<3,>=2.25.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/c1/24814557f1d22c56d50280771a17307e6bf87b70727d975fd6b2ce6b014a/requests-2.25.1-py2.py3-none-any.whl (61kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 61kB 6.7MB/s \n","\u001b[?25hCollecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 8.9MB/s \n","\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from rich<11,>=10.0.0->aicrowd-cli) (2.6.1)\n","Collecting colorama<0.5.0,>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Collecting commonmark<0.10.0,>=0.9.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b1/92/dfd892312d822f36c55366118b95d914e5f16de11044a27cf10a7d71bbbf/commonmark-0.9.1-py2.py3-none-any.whl (51kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 51kB 7.6MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions<4.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from rich<11,>=10.0.0->aicrowd-cli) (3.7.4.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (3.0.4)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.25.1->aicrowd-cli) (2.10)\n","Collecting smmap<5,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.25.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","Installing collected packages: smmap, gitdb, gitpython, requests, requests-toolbelt, colorama, commonmark, rich, tqdm, aicrowd-cli\n","  Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","Successfully installed aicrowd-cli-0.1.2 colorama-0.4.4 commonmark-0.9.1 gitdb-4.0.7 gitpython-3.1.14 requests-2.25.1 requests-toolbelt-0.9.1 rich-10.1.0 smmap-4.0.0 tqdm-4.60.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"D5L6NxEe_5TZ"},"source":["## Download Data\n","The first step is to download out train test data. We will be training a model on the train data and make predictions on test data. We submit our predictions.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lyF9gbdx_5TZ","executionInfo":{"status":"ok","timestamp":1618738080102,"user_tz":-330,"elapsed":6843,"user":{"displayName":"Dharmesh Gusai","photoUrl":"","userId":"00014665528927325987"}},"outputId":"b4d5f65e-53b9-4e11-8d2e-a90f5bd59357"},"source":["API_KEY = \"fd1aed7204268f0bae2780fb808a4063\" #Please enter your API Key from [https://www.aicrowd.com/participants/me]\n","!aicrowd login --api-key $API_KEY"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[32mAPI Key valid\u001b[0m\n","\u001b[32mSaved API Key successfully!\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hx8pHTHZ_5Ta","executionInfo":{"status":"ok","timestamp":1618738097591,"user_tz":-330,"elapsed":24327,"user":{"displayName":"Dharmesh Gusai","photoUrl":"","userId":"00014665528927325987"}},"outputId":"ba1a8749-eee9-4be5-ecd1-3e76e52f3bda"},"source":["!aicrowd dataset download --challenge chunin-exams-food-track-cv-2021"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train_images.zip: 100% 754M/754M [00:08<00:00, 90.5MB/s]\n","test_images.zip: 100% 33.9M/33.9M [00:00<00:00, 65.8MB/s]\n","train.csv: 100% 253k/253k [00:00<00:00, 3.07MB/s]\n","test.csv: 100% 7.27k/7.27k [00:00<00:00, 913kB/s]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BlFRoyNnUhTF"},"source":["!unzip train_images.zip\n","!unzip test_images.zip"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-GEKo1eOW1_l"},"source":["#Libraries"]},{"cell_type":"code","metadata":{"id":"qhJ2Rtr_Ggj2"},"source":["import cv2\n","import os\n","import csv\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","\n","import pandas as pd\n","import numpy as np\n","\n","import keras\n","import glob\n","import matplotlib.pyplot as plt\n","import scipy\n","import seaborn as sns\n","from mlxtend.preprocessing import minmax_scaling\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.model_selection import train_test_split\n","\n","from keras.utils.np_utils import to_categorical\n","from keras.layers import AveragePooling2D\n","from keras import layers\n","from keras.models import Sequential, Model\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, GlobalAveragePooling2D, Input, BatchNormalization, Multiply, Activation\n","from keras.optimizers import RMSprop, SGD\n","from keras.regularizers import l2\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.utils import plot_model\n","from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import confusion_matrix\n","from keras import backend as K\n","from keras.layers import GlobalMaxPooling2D\n","from keras.layers import GlobalAveragePooling2D\n","import tensorflow as tf\n","\n","from PIL import Image, ImageOps"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"A64FQL4wMoTL"},"source":["#Load data"]},{"cell_type":"code","metadata":{"id":"aOVv0dk2tGmS"},"source":["def load_images_from_folder(folder):\n","\n","  train_data=pd.read_csv('train.csv')\n","  images_names=train_data['ImageId']\n","\n","  X=[]\n","  for img_name in images_names:\n","    img = Image.open('train_images/'+img_name)\n","    X.append(img.convert('RGB').resize((128, 128), Image.ANTIALIAS))\n","\n","  return X\n","  \n","def load_labels(folder):\n","    with open(folder, mode='r') as csv_file:\n","        csv_reader = csv.DictReader(csv_file)\n","        labels = []  \n","        line_count = 0  \n","        for row in csv_reader:\n","            if line_count == 0:\n","                line_count += 1\n","            labels.append(row['ClassName'])\n","            line_count += 1\n","        \n","        return labels\n","    \n","\n","train_images = load_images_from_folder('./train.csv')\n","train_labels = load_labels('./train.csv')\n","test_images = load_images_from_folder('./test_images/')\n","train_images = np.array([np.array(x) for x in train_images])\n","train_images = train_images/255.\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Isz5XGjYFI6l"},"source":["le = LabelEncoder()\n","le.fit(train_labels)\n","train_labels_enc = le.transform(train_labels)\n","\n","onehot_encoder = OneHotEncoder(sparse=False)\n","integer_encoded = train_labels_enc.reshape(len(train_labels_enc), 1)\n","onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","\n","train_labels_enc = le.transform(train_labels)\n","\n","onehot_encoder = OneHotEncoder(sparse=False)\n","integer_encoded = train_labels_enc.reshape(len(train_labels_enc), 1)\n","onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","\n","train_labels = onehot_encoded "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tDRr_zj01NNN"},"source":["X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.15, random_state=42)\n","# X_train, y_train = train_images, train_labels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0tm4QJgYrgiN"},"source":["#For Part 2"]},{"cell_type":"code","metadata":{"id":"6ALph5Tm-9VD"},"source":["from tensorflow.keras.applications.inception_v3 import InceptionV3\n","pre_trained_model = InceptionV3(input_shape = (160, 160, 3), # Shape of our images\n","                                include_top = False, # Leave out the last fully connected layer\n","                                weights = 'imagenet')\n","for layer in pre_trained_model.layers:\n","  layer.trainable = False\n","\n","from tensorflow.keras.optimizers import RMSprop\n","\n","# Flatten the output layer to 1 dimension\n","x = layers.Flatten()(pre_trained_model.output)\n","# Add a fully connected layer with 1,024 hidden units and ReLU activation\n","x = layers.Dense(1024, activation='relu')(x)\n","# Add a dropout rate of 0.2\n","x = layers.Dropout(0.2)(x)                  \n","# Add a final sigmoid layer for classification\n","x = layers.Dense(61, activation='softmax')(x)           \n","\n","model = Model( pre_trained_model.input, x) \n","\n","model.compile(optimizer = RMSprop(lr=0.0001), \n","              loss = 'categorical_crossentropy', \n","              metrics = ['categorical_accuracy'])\n","\n","\n","train_datagen = ImageDataGenerator(\n","    rotation_range=40,      #rotation\n","    width_shift_range=0.2,  #translation with widht\n","    height_shift_range=0.2,  #translation with height\n","    brightness_range=[0.2,1.0] #color brighness change\n","    )\n","\n","model.fit(X_train, y_train, epochs = 30, batch_size = 32, validation_split=0.15)\n","# model.fit_generator(train_datagen.flow(X_train, y_train, batch_size = 32), validation_data = (X_val,y_val), steps_per_epoch = X_train.shape[0]/32,  epochs = 25)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1hSeGoNf8NEp","executionInfo":{"status":"ok","timestamp":1618681882832,"user_tz":-330,"elapsed":36651,"user":{"displayName":"Dharmesh gusai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMy5alBYUxR8nnI0piRM80xNZ3jJr9sW6-1XCGjQ=s64","userId":"06135295940734457600"}},"outputId":"4c7195e3-d181-499d-819e-a33df7fd04bc"},"source":["model.save('mymodel')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: mymodel/assets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"d-1D4hjwZFIf"},"source":["train_data=pd.read_csv('test.csv')\n","images_names=train_data['ImageId']\n","\n","X=[]\n","for img_name in images_names:\n","  img = Image.open('test_images/'+img_name)\n","  X.append(img.convert('RGB').resize((160, 160), Image.ANTIALIAS))\n","\n","\n","X = np.array([np.array(x) for x in X])\n","X = X / 255.\n","ans = model.predict(X)\n","\n","res = []\n","for i in range(ans.shape[0]):\n","  ind = np.argmax(ans[i])\n","  res.append(ind)\n","res = (le.inverse_transform(res))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-1m1MphhY0IF"},"source":["x= np.dstack((np.arange(0, res.size),res))[0]\n","np.savetxt(\"submission.csv\",x, fmt='%s', delimiter=\",\",header=\",ClassName\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rlIpaZ4zXOEc","executionInfo":{"status":"ok","timestamp":1618671933781,"user_tz":-330,"elapsed":36552,"user":{"displayName":"Dharmesh gusai","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgMy5alBYUxR8nnI0piRM80xNZ3jJr9sW6-1XCGjQ=s64","userId":"06135295940734457600"}},"outputId":"2d1e5876-c00a-4eed-b09f-81daebbb1ab1"},"source":["model.save('mymodel')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: mymodel/assets\n"],"name":"stdout"}]}]}